{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c34d172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:27:29.517177Z",
     "iopub.status.busy": "2023-12-20T16:27:29.516083Z",
     "iopub.status.idle": "2023-12-20T16:27:34.630497Z",
     "shell.execute_reply": "2023-12-20T16:27:34.629258Z"
    },
    "papermill": {
     "duration": 5.12549,
     "end_time": "2023-12-20T16:27:34.633446",
     "exception": false,
     "start_time": "2023-12-20T16:27:29.507956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import warnings  # Handling warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 🤐 Disable warnings to keep the code clean\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 📊 Define flags and variables\n",
    "is_train = False  # Flag for training mode\n",
    "is_infer = False\n",
    "\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c33292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:27:34.649701Z",
     "iopub.status.busy": "2023-12-20T16:27:34.649245Z",
     "iopub.status.idle": "2023-12-20T16:27:34.667201Z",
     "shell.execute_reply": "2023-12-20T16:27:34.665686Z"
    },
    "papermill": {
     "duration": 0.028404,
     "end_time": "2023-12-20T16:27:34.670125",
     "exception": false,
     "start_time": "2023-12-20T16:27:34.641721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7ff0f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:27:34.684281Z",
     "iopub.status.busy": "2023-12-20T16:27:34.683866Z",
     "iopub.status.idle": "2023-12-20T16:28:00.179028Z",
     "shell.execute_reply": "2023-12-20T16:28:00.177800Z"
    },
    "papermill": {
     "duration": 25.50586,
     "end_time": "2023-12-20T16:28:00.182154",
     "exception": false,
     "start_time": "2023-12-20T16:27:34.676294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 234.78 Mb (65.4% reduction)\n",
      "Shape of df:  (5237892, 17)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n",
    "# 🧹 Remove rows with missing values in the \"target\" column\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "# 🔁 Reset the index of the DataFrame and apply the changes in place\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = reduce_mem_usage(df)\n",
    "print(\"Shape of df: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31c119",
   "metadata": {
    "papermill": {
     "duration": 0.005926,
     "end_time": "2023-12-20T16:28:00.194458",
     "exception": false,
     "start_time": "2023-12-20T16:28:00.188532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b1b4be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:28:00.209887Z",
     "iopub.status.busy": "2023-12-20T16:28:00.208500Z",
     "iopub.status.idle": "2023-12-20T16:28:00.235258Z",
     "shell.execute_reply": "2023-12-20T16:28:00.233635Z"
    },
    "papermill": {
     "duration": 0.037714,
     "end_time": "2023-12-20T16:28:00.238406",
     "exception": false,
     "start_time": "2023-12-20T16:28:00.200692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_eng(data):\n",
    "    drop_cols = []\n",
    "    if 'row_id' in data.columns:\n",
    "        drop_cols.append('row_id')\n",
    "    if 'time_id' in data.columns:\n",
    "        drop_cols.append('time_id')\n",
    "    df=data.drop(drop_cols, axis=1)\n",
    "    df['trade_volume'] = df['bid_size'] + df['ask_size']\n",
    "    df['trade_ratio'] = df['bid_size'] / df['ask_size']\n",
    "    df['trade_volume_diff'] = df['bid_size'] - df['ask_size']\n",
    "    df['imbalance_ratio_1'] = df['imbalance_size'] / df['trade_volume']\n",
    "    df['imbalance_ratio_2'] = df['imbalance_size'] / df['trade_volume_diff']\n",
    "    df['imbalance_ratio_3'] = df['imbalance_size'] / df['matched_size']\n",
    "    df['mid_price'] = (df['bid_price'] + df['ask_price']) / 2\n",
    "    df['price_spread'] = df['bid_price'] - df['ask_price']\n",
    "    df['far_near_spread'] = df['far_price'] - df['near_price']\n",
    "    df['price_spread_ratio'] = df['price_spread'] / df['far_near_spread']\n",
    "    \n",
    "    # stock trading price max, min, std, med\n",
    "    # trading volume max, min, std, med\n",
    "    # diff price vs med\n",
    "    # diff trading volume vs med\n",
    "    stats_cols = [\n",
    "        'trade_volume', 'wap', 'reference_price', 'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size'\n",
    "    ]\n",
    "    df_by_stock = df[stats_cols+['stock_id']].groupby('stock_id').agg(['mean', 'std'])\n",
    "    df_by_stock.columns = [\"_\".join(x) for x in df_by_stock.columns.ravel()]\n",
    "    df = df.merge(df_by_stock, on='stock_id', how='left')\n",
    "    for col in [x for x in stats_cols if 'price' in x]:\n",
    "        df['wap_' + col+'_'+'diff'] = df['wap']-df[col]\n",
    "        df[col+'_mean_diff'] = df[col] - df[col+'_mean']\n",
    "        df[col+'_mean_diff_normed'] = df[col+'_mean_diff']/df[col+'_std']\n",
    "    \n",
    "    for col in ['wap', 'trade_volume', 'bid_size', 'ask_size']:\n",
    "        df[col +'_mean_diff'] = df[col] - df[col+'_mean']\n",
    "        df[col+'_mean_diff_normed'] = df[col+'_mean_diff'] / df[col+'_std']\n",
    "        \n",
    "    for col in stats_cols:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n",
    "\n",
    "    # avg/diff for same day and stock\n",
    "    day_cols = stats_cols + ['imbalance_size', 'matched_size']\n",
    "    df_by_stock_date = df[day_cols+['stock_id','date_id']].groupby(['stock_id', 'date_id']).mean()\n",
    "    df_by_stock_date.columns = [x+'_day_mean' for x in day_cols]\n",
    "    fst_by_stock_date = (df[day_cols+['stock_id','date_id', 'seconds_in_bucket']]\n",
    "                         .sort_values(['stock_id','date_id', 'seconds_in_bucket'])\n",
    "                         .groupby(['stock_id', 'date_id']).first()\n",
    "                        )\n",
    "    fst_by_stock_date.columns.values[:-1] = [x+'_day_start' for x in day_cols]\n",
    "    df = (df\n",
    "          .merge(fst_by_stock_date, on=['stock_id','date_id'], how='left')\n",
    "          .merge(df_by_stock_date, on=['stock_id','date_id'], how='left')\n",
    "         )\n",
    "    for col in day_cols:\n",
    "        df[col+'_diff_start'] = df[col] - df[col+'_day_start']\n",
    "        df[col+'_diff_day_mean'] = df[col] - df[col+'_day_mean']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5e7f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:28:00.255685Z",
     "iopub.status.busy": "2023-12-20T16:28:00.255214Z",
     "iopub.status.idle": "2023-12-20T16:28:32.194035Z",
     "shell.execute_reply": "2023-12-20T16:28:32.192169Z"
    },
    "papermill": {
     "duration": 31.951528,
     "end_time": "2023-12-20T16:28:32.197513",
     "exception": false,
     "start_time": "2023-12-20T16:28:00.245985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = feature_eng(df)\n",
    "y_train = df['target']\n",
    "X_train.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99672b",
   "metadata": {
    "papermill": {
     "duration": 0.006338,
     "end_time": "2023-12-20T16:28:32.211249",
     "exception": false,
     "start_time": "2023-12-20T16:28:32.204911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f2974f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:28:32.227693Z",
     "iopub.status.busy": "2023-12-20T16:28:32.227267Z",
     "iopub.status.idle": "2023-12-20T16:28:32.251731Z",
     "shell.execute_reply": "2023-12-20T16:28:32.250362Z"
    },
    "papermill": {
     "duration": 0.036018,
     "end_time": "2023-12-20T16:28:32.254972",
     "exception": false,
     "start_time": "2023-12-20T16:28:32.218954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.925638165305344, {'bagging_fraction': 0.8611136941833629, 'feature_fraction': 0.5735009541004218, 'learning_rate': 0.6919300183194385, 'max_bin': 76, 'max_depth': 26, 'min_data_in_leaf': 64, 'min_sum_hessian_in_leaf': 81.39493869656881, 'num_leaves': 176, 'subsample': 0.08833040944871326, 'objective': 'regression', 'metric': 'mae', 'n_estimators': 3000, 'reg_alpha': 0.1, 'reg_lambda': 0.3})\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=15, n_folds=4, random_seed=6, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(\n",
    "        learning_rate, num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,\n",
    "        min_sum_hessian_in_leaf,subsample, n_estimators, reg_alpha\n",
    "    ):\n",
    "        params = {'objective': 'regression', 'metric':'mae'}\n",
    "        params['learning_rate'] = max(min(learning_rate, 1), 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['max_bin'] = int(round(max_bin))\n",
    "        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "#         params['n_estimators'] = int(round(n_estimators)*100)\n",
    "#         params['reg_alpha'] = reg_alpha\n",
    "#         scores = cross_val_score(lgb.LGBMRegressor(random_state=random_seed, **params),\n",
    "#                              X_train, y_train, scoring='neg_mean_absolute_error', cv=n_folds).mean()\n",
    "#         return scores.mean()\n",
    "        \n",
    "        cv_result = lgb.cv(\n",
    "            params, train_data, nfold=5, seed=random_seed, stratified=False, metrics=['l1']\n",
    "        )\n",
    "        return max(cv_result['l1-mean'])\n",
    "\n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.01, 1.0),\n",
    "                                            'num_leaves': (64, 256),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (10, 30),\n",
    "                                            'max_bin':(30,90),\n",
    "                                            'min_data_in_leaf': (20, 80),\n",
    "                                            'min_sum_hessian_in_leaf':(10,90),\n",
    "                                            'subsample': (0.01, 1.0),\n",
    "                                            'n_estimators': (5, 10),\n",
    "                                            'reg_alpha': (0.01, 1.0)\n",
    "                                           })\n",
    "\n",
    "\n",
    "    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n",
    "\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "\n",
    "    model_mae=[]\n",
    "    for model in range(len(lgbBO.res)):\n",
    "        model_mae.append(lgbBO.res[model]['target'])\n",
    "\n",
    "    # return best parameters\n",
    "    return lgbBO.res[pd.Series(model_mae).idxmin()]['target'],lgbBO.res[pd.Series(model_mae).idxmin()]['params']\n",
    "\n",
    "if is_train:\n",
    "    opt_params = bayes_parameter_opt_lgb(X_train, y_train, n_folds=3)\n",
    "else:\n",
    "    # previously saved opt_params \n",
    "    opt_params = (5.925638165305344, {'bagging_fraction': 0.8611136941833629, 'feature_fraction': 0.5735009541004218, 'learning_rate': 0.6919300183194385, 'max_bin': 76, 'max_depth': 26, 'min_data_in_leaf': 64, 'min_sum_hessian_in_leaf': 81.39493869656881, 'num_leaves': 176, 'subsample': 0.08833040944871326, 'objective': 'regression', 'metric': 'mae', 'n_estimators': 3000, 'reg_alpha':0.1, 'reg_lambda':0.3})\n",
    "\n",
    "opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\n",
    "opt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\n",
    "opt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf']))\n",
    "opt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\n",
    "opt_params[1]['objective']='regression'\n",
    "opt_params[1]['metric']='mae'\n",
    "\n",
    "# k fold, best model\n",
    "print(opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac0b15",
   "metadata": {
    "papermill": {
     "duration": 0.006098,
     "end_time": "2023-12-20T16:28:32.268227",
     "exception": false,
     "start_time": "2023-12-20T16:28:32.262129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Time series cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0018cfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:28:32.284232Z",
     "iopub.status.busy": "2023-12-20T16:28:32.283728Z",
     "iopub.status.idle": "2023-12-20T16:28:32.293164Z",
     "shell.execute_reply": "2023-12-20T16:28:32.291677Z"
    },
    "papermill": {
     "duration": 0.021039,
     "end_time": "2023-12-20T16:28:32.295898",
     "exception": false,
     "start_time": "2023-12-20T16:28:32.274859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_series_cross_validation_split(num_folds, date_list):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_folds : int\n",
    "      The number of folds for which to split the data\n",
    "    date_list : list\n",
    "    \"\"\"\n",
    "    # Define percentages on which to split data based on rank and number of folds\n",
    "    date_list = np.sort(date_list)\n",
    "    date_pct_rank = np.array(date_list/len(date_list))\n",
    "    fold_percentage = 1 / (num_folds + 2)\n",
    "    train_dates = []\n",
    "    valid_dates = []\n",
    "    # For each fold\n",
    "    for i in range(2, num_folds + 1):\n",
    "        train_set = date_list[date_pct_rank<=fold_percentage * i]\n",
    "        valid_set = date_list[(date_pct_rank<=fold_percentage * (i+1))&(date_pct_rank>fold_percentage * i)]\n",
    "        \n",
    "        # Append to lists to return \n",
    "        train_dates.append(train_set)\n",
    "        valid_dates.append(valid_set)\n",
    "    return train_dates, valid_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbdb404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:28:32.311515Z",
     "iopub.status.busy": "2023-12-20T16:28:32.311043Z",
     "iopub.status.idle": "2023-12-20T16:28:36.660003Z",
     "shell.execute_reply": "2023-12-20T16:28:36.658420Z"
    },
    "papermill": {
     "duration": 4.360301,
     "end_time": "2023-12-20T16:28:36.662727",
     "exception": false,
     "start_time": "2023-12-20T16:28:32.302426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5735009541004218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5735009541004218\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=81.39493869656881, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=81.39493869656881\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611136941833629, subsample=0.08833040944871326 will be ignored. Current value: bagging_fraction=0.8611136941833629\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's l1: 6.26756\n",
      "[200]\tvalid_0's l1: 6.26756\n",
      "[300]\tvalid_0's l1: 6.26756\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's l1: 6.26756\n",
      "Fold 0 MAE: 6.251924886144627\n",
      "Fold 1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5735009541004218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5735009541004218\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=81.39493869656881, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=81.39493869656881\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611136941833629, subsample=0.08833040944871326 will be ignored. Current value: bagging_fraction=0.8611136941833629\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's l1: 6.2803\n",
      "[200]\tvalid_0's l1: 6.58003\n",
      "[300]\tvalid_0's l1: 6.66429\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's l1: 5.65908\n",
      "Fold 1 MAE: 5.659075853992732\n",
      "Fold 2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5735009541004218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5735009541004218\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=81.39493869656881, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=81.39493869656881\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611136941833629, subsample=0.08833040944871326 will be ignored. Current value: bagging_fraction=0.8611136941833629\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's l1: 5.30865\n",
      "[200]\tvalid_0's l1: 5.26167\n",
      "[300]\tvalid_0's l1: 4.9726\n",
      "[400]\tvalid_0's l1: 4.84782\n",
      "[500]\tvalid_0's l1: 4.79975\n",
      "[600]\tvalid_0's l1: 4.7639\n",
      "[700]\tvalid_0's l1: 4.73524\n",
      "[800]\tvalid_0's l1: 4.72506\n",
      "[900]\tvalid_0's l1: 4.72938\n",
      "[1000]\tvalid_0's l1: 4.73156\n",
      "[1100]\tvalid_0's l1: 4.71606\n",
      "[1200]\tvalid_0's l1: 4.70851\n",
      "[1300]\tvalid_0's l1: 4.70585\n",
      "[1400]\tvalid_0's l1: 4.70274\n",
      "[1500]\tvalid_0's l1: 4.71073\n",
      "[1600]\tvalid_0's l1: 4.71256\n",
      "Early stopping, best iteration is:\n",
      "[1361]\tvalid_0's l1: 4.69818\n",
      "Fold 2 MAE: 4.698181295218464\n",
      "Fold 3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5735009541004218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5735009541004218\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=81.39493869656881, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=81.39493869656881\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611136941833629, subsample=0.08833040944871326 will be ignored. Current value: bagging_fraction=0.8611136941833629\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's l1: 4.78877\n",
      "[200]\tvalid_0's l1: 4.53821\n",
      "[300]\tvalid_0's l1: 4.78861\n",
      "[400]\tvalid_0's l1: 4.83951\n",
      "[500]\tvalid_0's l1: 4.86987\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's l1: 4.53821\n",
      "Fold 3 MAE: 4.538207530462977\n",
      "CV Average MAE: 5.28685 \n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(len(y_train))\n",
    "scores = []\n",
    "feature_importance_df = pd.DataFrame()\n",
    "date_arr = np.array(X_train['date_id'].unique())\n",
    "train, valid = time_series_cross_validation_split(5, date_arr)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(zip(train, valid)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    reg = lgb.LGBMRegressor(**opt_params[1])\n",
    "    reg.fit(\n",
    "        X_train.iloc[trn_idx],\n",
    "        y_train.iloc[trn_idx],\n",
    "        eval_set=[(X_train.iloc[val_idx], y_train.iloc[val_idx])],\n",
    "        callbacks=[\n",
    "            lgb.callback.early_stopping(stopping_rounds=300),\n",
    "            lgb.callback.log_evaluation(period=100),\n",
    "        ],\n",
    "    )\n",
    "    preds[val_idx] = reg.predict(X_train.iloc[val_idx])\n",
    "#     reg = lgb.train(opt_params[1], trn_data, num_round, valid_sets = [trn_data, val_data])\n",
    "#     preds[val_idx] = reg.predict(X_train.iloc[val_idx], num_iteration=reg.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = X_train.columns\n",
    "    fold_importance_df[\"importance\"] = reg.feature_importances_ #feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    fold_score = mean_absolute_error(preds[val_idx], y_train[val_idx])\n",
    "    scores.append(fold_score)\n",
    "    print(f\"Fold {fold_} MAE: {fold_score}\")\n",
    "\n",
    "print(\"CV Average MAE: {:<8.5f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a9d8e",
   "metadata": {
    "papermill": {
     "duration": 0.00843,
     "end_time": "2023-12-20T16:28:36.680115",
     "exception": false,
     "start_time": "2023-12-20T16:28:36.671685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a35f6c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:28:36.700387Z",
     "iopub.status.busy": "2023-12-20T16:28:36.699989Z",
     "iopub.status.idle": "2023-12-20T16:28:36.707675Z",
     "shell.execute_reply": "2023-12-20T16:28:36.706433Z"
    },
    "papermill": {
     "duration": 0.020851,
     "end_time": "2023-12-20T16:28:36.710146",
     "exception": false,
     "start_time": "2023-12-20T16:28:36.689295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    # plot feature importance, feature selection\n",
    "    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "            .groupby(\"Feature\")\n",
    "            .mean()\n",
    "            .sort_values(by=\"importance\", ascending=False)[:20].index)\n",
    "    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "    plt.figure(figsize=(20,28))\n",
    "    sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "    plt.title('Features importance (averaged/folds)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bddf72",
   "metadata": {
    "papermill": {
     "duration": 0.008444,
     "end_time": "2023-12-20T16:28:36.727365",
     "exception": false,
     "start_time": "2023-12-20T16:28:36.718921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c792ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T16:28:36.747837Z",
     "iopub.status.busy": "2023-12-20T16:28:36.746974Z",
     "iopub.status.idle": "2023-12-20T16:28:36.760599Z",
     "shell.execute_reply": "2023-12-20T16:28:36.759655Z"
    },
    "papermill": {
     "duration": 0.026575,
     "end_time": "2023-12-20T16:28:36.762991",
     "exception": false,
     "start_time": "2023-12-20T16:28:36.736416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out\n",
    "\n",
    "if is_infer:\n",
    "    import optiver2023\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    counter = 0\n",
    "    y_min, y_max = -64, 64\n",
    "    qps, predictions = [], []\n",
    "    cache = pd.DataFrame()\n",
    "    \n",
    "    for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "        now_time = time.time()\n",
    "        cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "        if counter > 0:\n",
    "            cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "        feat = feature_eng(cache)[-len(test):]\n",
    "\n",
    "        # added after new API, reference: https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/455690#2526672\n",
    "#         if test.currently_scored.iloc[0]== False:\n",
    "#             print('test.currently_scored')\n",
    "#             sample_prediction['target'] = reg.predict(feat)\n",
    "#             env.predict(sample_prediction)\n",
    "#             counter += 1\n",
    "#             qps.append(time.time() - now_time)\n",
    "#             if counter % 10 == 0:\n",
    "#                 print(counter, 'qps:', np.mean(qps))\n",
    "#             continue\n",
    "\n",
    "        feat = feat.drop(columns = [\"currently_scored\"])    \n",
    "        # end of new codes for new API\n",
    "        \n",
    "        # Generate predictions for each model and calculate the weighted average\n",
    "        lgb_predictions = reg.predict(feat)\n",
    "\n",
    "        lgb_predictions = zero_sum(lgb_predictions, test['bid_size'] + test['ask_size'])\n",
    "        clipped_predictions = np.clip(lgb_predictions, y_min, y_max)\n",
    "        sample_prediction['target'] = clipped_predictions\n",
    "        print(sample_prediction)\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1\n",
    "        qps.append(time.time() - now_time)\n",
    "        if counter % 10 == 0:\n",
    "            print(counter, 'qps:', np.mean(qps))\n",
    "\n",
    "    time_cost = 1.146 * np.mean(qps)\n",
    "    print(f\"The code will take approximately {np.round(time_cost, 4)} hours to reason about\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee69b35",
   "metadata": {
    "papermill": {
     "duration": 0.0099,
     "end_time": "2023-12-20T16:28:36.781786",
     "exception": false,
     "start_time": "2023-12-20T16:28:36.771886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 73.243474,
   "end_time": "2023-12-20T16:28:37.915024",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-20T16:27:24.671550",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
